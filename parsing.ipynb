{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d0829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import etree, html as lhtml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284455f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 239/239 [01:35<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "req = requests.post(\"http://www.autonet.ru/auto/ttx\")\n",
    "tree = lhtml.fromstring(req.text)\n",
    "\n",
    "links = []\n",
    "for el, tag, link, pos in tqdm(list(tree.iterlinks())):\n",
    "    if link.startswith('/auto/ttx/'):\n",
    "        car = lhtml.fromstring(requests.post(f'http://www.autonet.ru{link}').text)\n",
    "        for _, _, car_link, _ in car.iterlinks():\n",
    "            if car_link.startswith(link+'/'):\n",
    "                links.append(f'http://www.autonet.ru{car_link}')\n",
    "\n",
    "cars_urls = pd.DataFrame({'url': links})\n",
    "cars_urls = cars_urls.sort_values(by='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1bb70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1820/1820 [33:16<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_info(modification):\n",
    "    res = {}\n",
    "    \n",
    "    res['name'] = modification.find('td', {'class': 'mod'}).text.strip()\n",
    "    \n",
    "    res['release_year'] = modification.find('td', {'class': 'edition'}).text.strip()\n",
    "    res['release_year'] = res['release_year'].split()[0].split('.')[-1]\n",
    "    res['release_year'] = int(res['release_year'])\n",
    "    \n",
    "    carcass = modification.find('td', {'class': 'carcass'}).text.strip()\n",
    "    res['carcass'] = carcass.split()[0]\n",
    "    res['doors'] = int(''.join(filter(str.isdigit, carcass)))\n",
    "\n",
    "    res['volume'] = modification.find('td', {'class': 'volume'}).text.strip()\n",
    "    volume = re.findall('[0-9]+', res['volume'])\n",
    "    res['volume'] = int(volume[0]) if len(volume) else 'None'\n",
    "\n",
    "    res['power'] = modification.find('td', {'class': 'power'}).text.strip()\n",
    "    power = re.findall('[0-9]+', res['power'])\n",
    "    res['power'] = int(power[0]) if len(power) else 'None'\n",
    "    \n",
    "    \n",
    "    links = []\n",
    "    for url in modification.find_all('td', {'class': 'mod'}):\n",
    "        links.append('http://www.autonet.ru' + url.a['href'])\n",
    "    res['url_auto'] = links[0]\n",
    "    \n",
    "    return res\n",
    "\n",
    "for link in tqdm(cars_urls['url'].unique()):\n",
    "    if str(link) == 'None':\n",
    "        continue\n",
    "        \n",
    "    req = requests.post(link)\n",
    "    soup = BeautifulSoup(req.text, 'html')\n",
    "    scrapped_info = []\n",
    "    for mark in soup.find_all(\"div\", {'class': 'mod-list'})[:-1] + soup.find_all(\"div\", {'class': 'mod-list bt-null'}):\n",
    "        for modification in mark.find_all('tr')[1:]:\n",
    "            scrapped_info.append(get_info(modification))\n",
    "            \n",
    "            \n",
    "    for idx in cars_urls[cars_urls['url'] == link].index:\n",
    "        applicable = []\n",
    "        for el in scrapped_info:\n",
    "            applicable.append(el)\n",
    "        \n",
    "        if len(applicable):\n",
    "            df = pd.DataFrame(applicable)\n",
    "            df = df.sort_values(by=['name', 'release_year', 'carcass', 'doors', 'volume', 'power', 'url_auto'])\n",
    "            for k, v in df.loc[0].items():\n",
    "                cars_urls.loc[idx, k] = v\n",
    "\n",
    "sub = cars_urls[['url'] + ['name', 'release_year', 'carcass', 'doors', 'volume', 'power', 'url_auto']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15319219",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.dropna(inplace=True)\n",
    "sub['model'] = sub.apply(lambda x: ' '.join(x['name'].split()[:len(x['url'].split('/')[-2].split('_'))]),\n",
    "                           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "713f1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b032e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1799/1799 [35:21<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "full_characteristics = []\n",
    "image_auto = []\n",
    "description_auto = []\n",
    "\n",
    "for link in tqdm(sub['url_auto'].values):\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.post(link).text, 'html')\n",
    "        full_characteristics.append('http://www.autonet.ru' + \\\n",
    "                                    soup.find('div', {'class': 'mod-characteristics-over'}).img['src'])\n",
    "        try:\n",
    "            image_auto.append(soup.find('div', {'id': 'slider'}).img['src'] if not None else 'None')\n",
    "        except TypeError:\n",
    "            image_auto.append('None')\n",
    "        description_auto.append(str(soup.find('div', {'class': 'mod-description'}).p)[3:-4])\n",
    "    except ConnectionError:\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "sub['full_characteristics_url'] = pd.Series(full_characteristics)\n",
    "sub['image_auto_url'] = pd.Series(image_auto)\n",
    "sub['desription_auto'] = pd.Series(description_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60395497",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata.to_csv('database.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
